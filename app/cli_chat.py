import os
import openai
import numpy as np
import faiss
from utils.common import load_json, get_embedding, ask_llm

# OpenAI API í‚¤ ì„¤ì •
openai.api_key = os.getenv("OPENAI_API_KEY")

# íŒŒì¼ ê²½ë¡œ
FAISS_INDEX_PATH = "./data/faiss.index"
CHUNK_METADATA_PATH = "./data/chunk_metadata.json"

# ì¸ë±ìŠ¤ ë° ì²­í¬ ë¡œë“œ
index = faiss.read_index(FAISS_INDEX_PATH)
chunks = load_json(CHUNK_METADATA_PATH)

# ê²€ìƒ‰ í•¨ìˆ˜
def search_chunks(question, top_k=3):
    q_emb = np.array([get_embedding(question)], dtype="float32")
    distances, indices = index.search(q_emb, top_k)
    return [chunks[i] for i in indices[0]]

# ì‹¤í–‰ ë¶€ë¶„
if __name__ == "__main__":
    question = input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")
    context = "\n\n---\n\n".join(search_chunks(question))
    print("ğŸ“š Context:\n", context[:500])  # ë¯¸ë¦¬ë³´ê¸° ì¶œë ¥
    answer = ask_llm(context, question)
    print("ğŸ§  GPT ì‘ë‹µ:\n", answer)
